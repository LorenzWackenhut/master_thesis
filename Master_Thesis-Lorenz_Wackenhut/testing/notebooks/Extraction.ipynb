{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pyspark\n",
                "from pyspark.sql.types import *\n",
                "from pyspark import SparkContext\n",
                "from pyspark.sql import SparkSession\n",
                "from pyspark.sql import SQLContext\n",
                "import pyspark.sql.functions as F"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "account_name = \"REDACTED\"\n",
                "account_key = \"REDACTED\"\n",
                "\n",
                "spark = (\n",
                "    SparkSession\n",
                "        .builder\n",
                "        .master('local[*]')\n",
                "        .appName(\"Ingestion\")\n",
                "        .config(\"spark.driver.memory\", \"4g\")\n",
                "        .config(\"fs.azure.account.auth.type.\" + account_name + \".dfs.core.windows.net\", \"SharedKey\")\n",
                "        .config(\"fs.azure.account.key.\" + account_name + \".dfs.core.windows.net\", account_key)\n",
                "        .getOrCreate()\n",
                ")\n",
                "\n",
                "sc = spark.sparkContext"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "container_name = 'data'\n",
                "path_to_table = '/masterdata/'\n",
                "\n",
                "def readDataframeFromAdls(spark_session, container_name, path_to_table, table_name):\n",
                "    return spark_session.read.parquet(f\"abfss://{container_name}@REDACTED.dfs.core.windows.net{path_to_table}{table_name}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_qb_file = (\n",
                "    readDataframeFromAdls(spark, container_name, path_to_table, 'df_qb_file')\n",
                "        .select(['ID_FILE'])\n",
                ")\n",
                "\n",
                "df_qd_state = (\n",
                "    readDataframeFromAdls(spark, container_name, path_to_table, 'df_qd_state')\n",
                "        .select(['ID', 'ID_FILE', 'DAY', 'MONTH', 'YEAR', 'STIME', 'STYPE', 'ACTIVITY_STATE', 'ACTIVITY_CONFID'])\n",
                "        .withColumn('STIME_SEC', F.round((F.col('STIME') / 1000)).cast(IntegerType()))\n",
                "        .withColumnRenamed('ID', 'ID_STATE')\n",
                ")\n",
                "\n",
                "df_qd_state_gps = (\n",
                "    readDataframeFromAdls(spark, container_name, path_to_table, 'df_qd_state_gps')\n",
                "        .select(['ID_STATE', 'ID_FILE', 'LTIME', 'SOURCE', 'SPEED', 'ACCURACY', 'LON', 'LAT'])\n",
                "        .withColumn('LTIME_SEC', F.round((F.col('LTIME') / 1000)).cast(IntegerType()))\n",
                ")\n",
                "\n",
                "df_qd_state_cell = (\n",
                "    readDataframeFromAdls(spark, container_name, path_to_table, 'df_qd_state_cell')\n",
                "        .select(['ID_STATE', 'ID_FILE', 'TYPE', 'LEVEL', 'QUAL', 'SLOT'])\n",
                ")\n",
                "\n",
                "df_qd_state_wifi = (\n",
                "    readDataframeFromAdls(spark, container_name, path_to_table, 'df_qd_state_wifi')\n",
                "        .select(['ID_STATE', 'ID_FILE'])\n",
                "        .withColumn('WIFI_CONNECTED', F.col('ID_STATE'))\n",
                ")\n",
                "\n",
                "df_qd_state_sense = (\n",
                "    readDataframeFromAdls(spark, container_name, path_to_table, 'df_qd_state_sens')\n",
                "        .select(['ID_STATE', 'ID_FILE', 'LIGHT', 'MAGNET_X', 'MAGNET_Y', 'MAGNET_Z', 'PROXIMITY'])\n",
                "        .withColumn('MAGNET_X', F.when(\n",
                "            (F.abs(F.col('MAGNET_X')) < 100000), F.col('MAGNET_X'))\n",
                "            .otherwise(F.lit(None)))\n",
                "        .withColumn('MAGNET_Y', F.when(\n",
                "            (F.abs(F.col('MAGNET_X')) < 100000), F.col('MAGNET_X'))\n",
                "            .otherwise(F.lit(None)))\n",
                "        .withColumn('MAGNET_Z', F.when(\n",
                "            (F.abs(F.col('MAGNET_X')) < 100000), F.col('MAGNET_X'))\n",
                "            .otherwise(F.lit(None)))\n",
                ")\n",
                "\n",
                "df_qd_state_batt = (\n",
                "    readDataframeFromAdls(spark, container_name, path_to_table, 'df_qd_state_batt')\n",
                "        .select(['ID_STATE', 'ID_FILE', 'BATT_CHARGE'])\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "condition_qdState_qbFile = ['ID_FILE']\n",
                "condition_qdState_qdStateGps = [\n",
                "    (df_qd_state.ID_STATE == df_qd_state_gps.ID_STATE) & \n",
                "    (df_qd_state.ID_FILE == df_qd_state_gps.ID_FILE) &\n",
                "    (df_qd_state_gps.LON.between(-180, 180)) & \n",
                "    (df_qd_state_gps.LAT.between(-90, 90))\n",
                "]\n",
                "condition_qdState_qdStateCell = [\n",
                "    (df_qd_state.ID_STATE == df_qd_state_cell.ID_STATE) &\n",
                "    (df_qd_state.ID_FILE == df_qd_state_cell.ID_FILE) &\n",
                "    (df_qd_state_cell.SLOT == 0)\n",
                "]\n",
                "condition_qdState_qdStateWifi = ['ID_FILE', 'ID_STATE']\n",
                "condition_qdState_qdStateSense = ['ID_FILE', 'ID_STATE']\n",
                "condition_qdState_qdStateBatt = ['ID_FILE', 'ID_STATE']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_join = (\n",
                "    df_qd_state\n",
                "        .join(F.broadcast(df_qb_file), on=condition_qdState_qbFile, how='inner')\n",
                "        .join(F.broadcast(df_qd_state_gps), on=condition_qdState_qdStateGps, how='inner')\n",
                "        .drop(df_qd_state_gps.ID_FILE).drop(df_qd_state_gps.ID_STATE)\n",
                "        .join(F.broadcast(df_qd_state_cell), on=condition_qdState_qdStateCell, how='left')\n",
                "        .drop(df_qd_state_cell.ID_FILE).drop(df_qd_state_cell.ID_STATE)\n",
                "        .join(F.broadcast(df_qd_state_wifi), on=condition_qdState_qdStateWifi, how='left')\n",
                "        .join(F.broadcast(df_qd_state_sense), on=condition_qdState_qdStateSense, how='left')\n",
                "        .join(F.broadcast(df_qd_state_batt), on=condition_qdState_qdStateBatt, how='left')\n",
                "        .cache()\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_wifi = (\n",
                "    df_join\n",
                "    .withColumn('WIFI_CONNECTED',\n",
                "        F.when(F.col('WIFI_CONNECTED').isNotNull(), True)\n",
                "        .otherwise(False)\n",
                "    )\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "container_name = 'data'\n",
                "path_to_table = '/extraction/'\n",
                "\n",
                "def writeDataframeToAdls(dataframe, container_name, path_to_table, table_name, mode='overwrite'):\n",
                "    (dataframe\n",
                "        .write\n",
                "        .mode(mode)\n",
                "        .format(\"table_name\")\n",
                "        .parquet(f\"abfss://{container_name}@REDACTED.dfs.core.windows.net{path_to_table}{table_name}\")\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": [
                "writeDataframeToAdls(df_wifi, container_name, path_to_table, \"df_extract\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}